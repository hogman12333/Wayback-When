# Wayback When


Wayback When Finds every page: Uses a "headless" browser to crawl a website and discover all its internal links.

Archives smartly: Checks if a page was saved recently to avoid wasting time on redundant backups based on user settings.

# V1.1 Release

# New Additions and Enhancements in V1.1

## ~~Max File size~~
-  Impliment a user chosen max file size, so when uploading Websites, it does not download too many files

## Further Optimisation
- Optimise and speed up Scraping and archiving, while keeping Memory And CPU usage as low as possible

## Add Download Support-not gonna release with v1.1, possibly might impliment it with an eventual GUI release
- Add support for downloading all previous versions of a website
- Idd this to settings so it can be chosen by the end user
- Idd uploading and downloading concurrently to maximise efficiency

## ~~Add user set cooldown when searching~~
- In order to prevent IP blocks and to improve stealth

## ~~Cleaner code~~
- See if separating code from main.py is feasable
## Contributing

Pull requests are welcome. For major changes, please open an issue first
to discuss what you would like to change.
